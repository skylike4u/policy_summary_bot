from openai import OpenAI
import feedparser
import os
from dotenv import load_dotenv
import json
from datetime import datetime

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 2. í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ì„¤ì • (2ì°¨ í•„í„°ë¡œë§Œ ì‚¬ìš©)
keywords = [
    "ì •ì±…", "ê³µëª¨", "ì§€ì›", "ì‚¬ì—…", "ì˜ˆì‚°", "ê³„íš",
    "ì²­ë…„", "ì‚°ì—…", "R&D", "ì†Œìƒê³µì¸", "ì²­ë…„ì •ì±…", "ì¼ìë¦¬", "ê¸°ì—…",
    "ì‚°ì—…ë‹¨ì§€", "AI", "ì¤‘ì†Œê¸°ì—…", "ë°œí‘œ", "ê³µê°œ", "ì‚°ë‹¨",
    "ë¶€ì‚°", "ì§€ìì²´", "ì§€ì—­", "í–‰ì‚¬", "í¬ëŸ¼", "ì„¤ëª…íšŒ",
    "ë°•ëŒíšŒ", "ì„¸ë¯¸ë‚˜", "ê°„ë‹´íšŒ", "ì‚¬íšŒì ê²½ì œ",
    "ë³µì§€", "ì£¼ê±°", "ëŒë´„", "ì˜ë£Œ", "íƒ„ì†Œì¤‘ë¦½", "ESG",
    "ë°•í˜•ì¤€", "ì‹œì¥", "ê¸°íšŒ", "ë¯¸ë˜", "í˜ì‹ "
]

# 3. rss_sources.json íŒŒì¼ì—ì„œ RSS ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
with open("rss_sources.json", "r", encoding="utf-8") as f:
    rss_data = json.load(f)

rss_urls_by_group = rss_data

# 4. ê·¸ë£¹ë³„ ìš”ì•½ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
summaries_by_group = {
    "ë¶€ì‚°ê´‘ì—­ì‹œ": [],
    "ì¤‘ì•™ì •ë¶€": [],
    "ê³µê³µê¸°ê´€/ê¸°íƒ€": []
}

# 5. ëª¨ë¸ ì„¤ì •
MODEL_NAME = "gpt-3.5-turbo"  # ë˜ëŠ” "gpt-4"

# 5-1. ëª¨ë¸ì— ë”°ë¥¸ ìš”ì•½ ë²”ìœ„ ìë™ ì„¤ì •
if MODEL_NAME == "gpt-4":
    MAX_ENTRIES = 12
    MAX_SNIPPET_CHARS = 600
else:
    MAX_ENTRIES = 6
    MAX_SNIPPET_CHARS = 300

# 6. ê° ê·¸ë£¹ë³„ RSS URL ì²˜ë¦¬
for group, urls in rss_urls_by_group.items():
    for rss_url in urls:
        feed = feedparser.parse(rss_url)
        entries = feed.entries[:MAX_ENTRIES]

        article_snippets = []
        for i, entry in enumerate(entries):
            title = entry.title.strip()
            summary = (entry.get("summary", "") or entry.get("description", "")).strip()
            snippet = summary if len(summary) < MAX_SNIPPET_CHARS else summary[:MAX_SNIPPET_CHARS] + "..."
            article_snippets.append(f"{i+1}. ì œëª©: {title}\nìš”ì•½: {snippet}")

        article_block = "\n\n".join(article_snippets)

        select_prompt = f"""
ë‹¤ìŒì€ ìµœê·¼ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì˜ ì œëª©ê³¼ ê°„ë‹¨í•œ ìš”ì•½ì…ë‹ˆë‹¤. ì´ ì¤‘ ì •ì±…ì  ê°€ì¹˜ê°€ ìˆê±°ë‚˜ ìš”ì•½í•  ë§Œí•œ ì˜ë¯¸ê°€ ìˆëŠ” ê¸°ì‚¬ ë²ˆí˜¸ë§Œ ê³¨ë¼ì¤˜.
í˜•ì‹: [1, 3, 5] â† ìˆ«ì ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•´ì¤˜.

ê¸°ì‚¬ ëª©ë¡:
{article_block}
"""

        try:
            selection_response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì •ì±…ì¡°ì •íŒ€ì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ì¤‘ìš”í•œ ì •ì±… ê¸°ì‚¬ë§Œ ì¶”ë ¤ì•¼ í•´."},
                    {"role": "user", "content": select_prompt}
                ],
                temperature=0.2,
            )
            raw_content = selection_response.choices[0].message.content.strip()
            if not raw_content.startswith("[") or not raw_content.endswith("]"):
                raise ValueError(f"GPT ë°˜í™˜ ì˜¤ë¥˜: {raw_content}")
            selected_indices = eval(raw_content)

        except Exception as e:
            group = "ê³µê³µê¸°ê´€/ê¸°íƒ€" if group == "ì‚°í•˜ê¸°ê´€" else group
            summaries_by_group.setdefault(group, []).append(f"â— ê¸°ì‚¬ ì„ íƒ ì‹¤íŒ¨: {e}\n\n")
            continue

        for idx in selected_indices:
            try:
                entry = entries[int(idx)-1]
                title = entry.title.strip()
                summary = (entry.get("summary", "") or entry.get("description", "")).strip()
                link = entry.link
                full_text = f"{title}\n{summary}"

                if not any(keyword in full_text for keyword in keywords):
                    continue

                prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •ì±… ê´€ë ¨ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜.

â€» ê¸°ì‚¬ ê°„ ë‚´ìš©ì´ ë¹„ìŠ·í•  ê²½ìš°, ì¤‘ë³µ ìš”ì•½ì„ í”¼í•˜ê³  ê°€ì¥ ì •ë³´ê°€ êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ê¸°ì‚¬ë§Œ ì„ íƒí•´ ìš”ì•½í•´ì¤˜.
â€» ê°™ì€ ì£¼ì œë¥¼ ë‹¤ë£¬ ì—¬ëŸ¬ ê¸°ì‚¬ëŠ” ìƒëµí•˜ê±°ë‚˜ ê°„ëµíˆ ì–¸ê¸‰í•´ë„ ê´œì°®ì•„.

ì œëª©: {title}

ë‚´ìš©: {summary}

### âœ¨ ê¸°ì‚¬ ìœ í˜•
(ì •ì±…ê³µê³  / ê³µëª¨ì „ / ì„¤ëª…íšŒ / í†µê³„ë™í–¥ / ì¸í„°ë·° / ì¼ë°˜ë³´ë„ / ê¸°íƒ€ ì¤‘ íŒë‹¨)

### ğŸ“Œ í•µì‹¬ ìš”ì•½ (2~3ì¤„)

### ğŸ“‹ ì£¼ìš” ë‚´ìš©
(ì§€ì› ëŒ€ìƒ, ì¡°ê±´, ì£¼ìš” ë°œí‘œ, ì •ì±… ë³€í™” ë“± í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬)

### ğŸ“… ì¼ì • ì •ë³´
(ê³µê³ ì¼, ì ‘ìˆ˜ ê¸°ê°„, í–‰ì‚¬ì¼ ë“± ê°€ëŠ¥í•˜ë©´ ëª…ì‹œ)

### ğŸ¢ ë°œì‹ ê¸°ê´€ ë˜ëŠ” ì£¼ìµœê¸°ê´€
â€» ê¸°ì‚¬ ì•ˆì— ëª…í™•íˆ ëª…ì‹œëœ ê²½ìš°ë§Œ ê¸°ì¬.
â€» "ë¬¸ì˜ì²˜"(ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“±)ê°€ ìˆë‹¤ë©´ ê¸°ì‚¬ì— ëª…ì‹œëœ ê²½ìš°ë§Œ ì‘ì„±. ì—†ìœ¼ë©´ ìƒëµ.
â€» ê¸°ì‚¬ì— ë“±ì¥í•˜ì§€ ì•ŠëŠ” ê¸°ê´€ëª…(ì˜ˆ: ë¶€ì‚°ê²½ì œì§„í¥ì›)ì€ ì ˆëŒ€ ì„ì˜ë¡œ ë„£ì§€ ë§ ê²ƒ.


â€» Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±.
â€» ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ í•´ë‹¹ í•­ëª©ì€ ìƒëµí•´ë„ ë˜ê³ , ì„ì˜ ì¶”ë¡ ì€ í•˜ì§€ ë§ ê²ƒ.
"""

                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ë¶€ì‚°ê²½ì œì§„í¥ì› ì •ì±…ì¡°ì •íŒ€ì˜ ìŠ¤ë§ˆíŠ¸ ìš”ì•½ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                )
                summaries_by_group.setdefault(group, []).append(
                    f"### ğŸ¯ {title}\nğŸ”— {link}\n\n" + response.choices[0].message.content + "\n\n---\n"
                )

            except Exception as e:
                group = "ê³µê³µê¸°ê´€/ê¸°íƒ€" if group == "ì‚°í•˜ê¸°ê´€" else group
                summaries_by_group.setdefault(group, []).append(f"â— [{title}] ì˜¤ë¥˜ ë°œìƒ: {e}\n\n")

# 7. Markdown íŒŒì¼ë¡œ ì €ì¥
today = datetime.now()
date_title = today.strftime("%Y.%m.%d")
output_file = f"policy_report_{today.strftime('%Y-%m-%d')}.md"

with open(output_file, "w", encoding="utf-8") as f:
    f.write(f"# ğŸ—‚ï¸ ë¶€ì‚°ê²½ì œì§„í¥ì› ì •ì±…ì¡°ì •íŒ€ ì •ì±… ë¦¬í¬íŠ¸\n")
    f.write(f"**ê¸°ì¤€ì¼ì: {date_title} ({today.strftime('%A')})**\n\n")
    f.write("---\n\n")

    if summaries_by_group["ë¶€ì‚°ê´‘ì—­ì‹œ"]:
        f.write("## 1. ë¶€ì‚°ê´‘ì—­ì‹œ ê´€ë ¨ ê¸°ì‚¬\n\n")
        f.writelines(summaries_by_group["ë¶€ì‚°ê´‘ì—­ì‹œ"])

    if summaries_by_group["ì¤‘ì•™ì •ë¶€"]:
        f.write("## 2. ì¤‘ì•™ë¶€ì²˜ ê´€ë ¨ ê¸°ì‚¬\n\n")
        f.writelines(summaries_by_group["ì¤‘ì•™ì •ë¶€"])

    if summaries_by_group["ê³µê³µê¸°ê´€/ê¸°íƒ€"]:
        f.write("## 3. ê³µê³µê¸°ê´€ ë° ê¸°íƒ€ ê¸°ì‚¬\n\n")
        f.writelines(summaries_by_group["ê³µê³µê¸°ê´€/ê¸°íƒ€"])

    f.write("---\n")
    total_count = sum(len(v) for v in summaries_by_group.values())
    f.write(f"\nì´ ìš”ì•½ ê¸°ì‚¬ ìˆ˜: {total_count}\n")

print(f"âœ… ìš”ì•½ ì™„ë£Œ! ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ â†’ {output_file}")
print(f"ğŸ“ ë³´ê³ ì„œë¥¼ PDFë¡œ ë³€í™˜í•˜ë ¤ë©´ 'report_converter.py' íŒŒì¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
